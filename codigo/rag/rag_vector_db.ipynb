{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/sonder-art/automl_o24/blob/main/codigo/rag/rag_vector_db.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced RAG System with Vector Databases\n",
    "\n",
    "This notebook implements a flexible RAG (Retrieval Augmented Generation) system with the following features:\n",
    "- Configurable embedding models with GPU support\n",
    "- Multiple document format support (txt, pdf, html, xml)\n",
    "- Smart document processing with caching\n",
    "- Flexible chunking strategies\n",
    "- Efficient vector storage using LanceDB\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers lancedb pandas numpy beautifulsoup4 PyPDF2 tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uumami/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import lancedb\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Union\n",
    "import json\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "from dataclasses import dataclass, asdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Enhanced configuration system with easy parameter modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Documents path: vector_store/documents\n",
      "Database path: vector_store/db\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class RAGConfig:\n",
    "    # Model Configuration\n",
    "    embedding_model: str = \"BAAI/bge-small-en-v1.5\"  # Better default model\n",
    "    use_gpu: bool = torch.cuda.is_available()\n",
    "    device: str = \"cuda\" if use_gpu else \"cpu\"\n",
    "    \n",
    "    # Storage Configuration\n",
    "    use_drive: bool = False  # For Google Colab\n",
    "    base_path: str = None  # Will be set in post_init\n",
    "    \n",
    "    # Chunking Configuration\n",
    "    chunk_size: int = 500\n",
    "    chunk_overlap: int = 50\n",
    "    \n",
    "    # Document Processing\n",
    "    supported_formats: List[str] = None  # Will be set in post_init\n",
    "    overwrite_existing: bool = False\n",
    "    \n",
    "    # Retrieval Configuration\n",
    "    top_k: int = 3\n",
    "    distance_metric: str = \"cosine\"\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Set base paths\n",
    "        if self.use_drive and IN_COLAB:\n",
    "            print(\"Mounting Google Drive...\")\n",
    "            drive.mount('/content/drive')\n",
    "            self.base_path = Path('/content/drive/MyDrive/vector_db')\n",
    "        else:\n",
    "            self.base_path = Path('vector_store')\n",
    "            \n",
    "        self.docs_path = self.base_path / 'documents'\n",
    "        self.db_path = self.base_path / 'db'\n",
    "        \n",
    "        # Create directories\n",
    "        self.docs_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.db_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Set supported formats\n",
    "        if self.supported_formats is None:\n",
    "            self.supported_formats = [\"txt\", \"pdf\", \"html\", \"xml\"]\n",
    "            \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(f\"Documents path: {self.docs_path}\")\n",
    "        print(f\"Database path: {self.db_path}\")\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save configuration to file\"\"\"\n",
    "        config_data = asdict(self)\n",
    "        config_data['base_path'] = str(self.base_path)\n",
    "        config_data['docs_path'] = str(self.docs_path)\n",
    "        config_data['db_path'] = str(self.db_path)\n",
    "        \n",
    "        config_path = self.base_path / 'config.json'\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config_data, f, indent=2)\n",
    "            \n",
    "    @classmethod\n",
    "    def load(cls, base_path: Optional[str] = None) -> 'RAGConfig':\n",
    "        \"\"\"Load configuration from file\"\"\"\n",
    "        if base_path is None:\n",
    "            if IN_COLAB:\n",
    "                base_path = '/content/drive/MyDrive/vector_db'\n",
    "            else:\n",
    "                base_path = 'vector_store'\n",
    "                \n",
    "        config_path = Path(base_path) / 'config.json'\n",
    "        if config_path.exists():\n",
    "            with open(config_path) as f:\n",
    "                config_data = json.load(f)\n",
    "            return cls(**config_data)\n",
    "        return cls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "config = RAGConfig()\n",
    "config.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Document Processing\n",
    "\n",
    "Improved document processor with multiple format support and smart caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        self.model = SentenceTransformer(config.embedding_model, device=config.device)\n",
    "        \n",
    "    def _compute_file_hash(self, file_path: str) -> str:\n",
    "        \"\"\"Compute SHA-256 hash of a file.\"\"\"\n",
    "        sha256_hash = hashlib.sha256()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "                sha256_hash.update(byte_block)\n",
    "        return sha256_hash.hexdigest()\n",
    "    \n",
    "    def _read_txt(self, file_path: str) -> str:\n",
    "        \"\"\"Read text from a txt file.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def _read_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Read text from a PDF file.\"\"\"\n",
    "        text = \"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    \n",
    "    def _read_html(self, file_path: str) -> str:\n",
    "        \"\"\"Read text from an HTML file.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "            return soup.get_text()\n",
    "    \n",
    "    def _read_xml(self, file_path: str) -> str:\n",
    "        \"\"\"Read text from an XML file.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'xml')\n",
    "            return soup.get_text()\n",
    "            \n",
    "    def process_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), self.config.chunk_size - self.config.chunk_overlap):\n",
    "            chunk = ' '.join(words[i:i + self.config.chunk_size])\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def process_file(self, file_path: str) -> Dict:\n",
    "        \"\"\"Process a single file with caching support.\"\"\"\n",
    "        file_ext = file_path.split('.')[-1].lower()\n",
    "        if file_ext not in self.config.supported_formats:\n",
    "            raise ValueError(f\"Unsupported file format: {file_ext}\")\n",
    "            \n",
    "        # Check cache\n",
    "        file_hash = self._compute_file_hash(file_path)\n",
    "        cache_path = self.config.docs_path / f\"{file_hash}.json\"\n",
    "        \n",
    "        if cache_path.exists() and not self.config.overwrite_existing:\n",
    "            logger.info(f\"Loading cached processing for {file_path}\")\n",
    "            with open(cache_path) as f:\n",
    "                return json.load(f)\n",
    "        \n",
    "        # Read content based on file type\n",
    "        readers = {\n",
    "            'txt': self._read_txt,\n",
    "            'pdf': self._read_pdf,\n",
    "            'html': self._read_html,\n",
    "            'xml': self._read_xml\n",
    "        }\n",
    "        \n",
    "        text = readers[file_ext](file_path)\n",
    "        chunks = self.process_text(text)\n",
    "        \n",
    "        # Use GPU for batch processing if available\n",
    "        embeddings = self.model.encode(chunks, show_progress_bar=True)\n",
    "        \n",
    "        result = {\n",
    "            'chunks': chunks,\n",
    "            'embeddings': embeddings.tolist(),\n",
    "            'source': str(file_path),\n",
    "            'file_hash': file_hash\n",
    "        }\n",
    "        \n",
    "        # Cache result\n",
    "        with open(cache_path, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def process_directory(self, dir_path: Optional[str] = None, table_name: str = 'documents') -> None:\n",
    "        \"\"\"Process all supported files in a directory.\"\"\"\n",
    "        dir_path = Path(dir_path) if dir_path else self.config.docs_path\n",
    "        db = lancedb.connect(self.config.db_path)\n",
    "        \n",
    "        all_data = []\n",
    "        for ext in self.config.supported_formats:\n",
    "            for file_path in dir_path.glob(f\"**/*.{ext}\"):\n",
    "                try:\n",
    "                    logger.info(f\"Processing {file_path}...\")\n",
    "                    result = self.process_file(str(file_path))\n",
    "                    \n",
    "                    for chunk, embedding in zip(result['chunks'], result['embeddings']):\n",
    "                        all_data.append({\n",
    "                            'text': chunk,\n",
    "                            'vector': embedding,\n",
    "                            'source': result['source'],\n",
    "                            'file_hash': result['file_hash']\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing {file_path}: {str(e)}\")\n",
    "        \n",
    "        if all_data:\n",
    "            df = pd.DataFrame(all_data)\n",
    "            if table_name in db.table_names():\n",
    "                table = db.open_table(table_name)\n",
    "                # Convert PyArrow Table to Pandas DataFrame correctly\n",
    "                existing_data = table.to_arrow().to_pandas()\n",
    "                if not existing_data.empty:\n",
    "                    existing_hashes = set(existing_data['file_hash'].unique())\n",
    "                    new_data = df[~df['file_hash'].isin(existing_hashes)]\n",
    "                    if not new_data.empty:\n",
    "                        table.add(new_data)\n",
    "                        logger.info(f\"Added {len(new_data)} new chunks to the database\")\n",
    "                    else:\n",
    "                        logger.info(\"No new documents to add\")\n",
    "                else:\n",
    "                    table.add(df)\n",
    "                    logger.info(f\"Added {len(df)} chunks to empty table\")\n",
    "            else:\n",
    "                db.create_table(table_name, df)\n",
    "                logger.info(f\"Created new table with {len(df)} chunks\")\n",
    "        else:\n",
    "            logger.info(\"No documents found to process\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Vector Database Operations\n",
    "\n",
    "Improved vector database class with better search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorDB:\n",
    "    def __init__(self, config: RAGConfig):\n",
    "        self.config = config\n",
    "        self.db = lancedb.connect(config.db_path)\n",
    "        self.model = SentenceTransformer(config.embedding_model, device=config.device)\n",
    "    \n",
    "    def list_tables(self) -> List[str]:\n",
    "        \"\"\"List all tables in the database.\"\"\"\n",
    "        return self.db.table_names()\n",
    "    \n",
    "    def get_table_info(self, table_name: str) -> Dict:\n",
    "        \"\"\"Get detailed information about a table.\"\"\"\n",
    "        table = self.db.open_table(table_name)\n",
    "        df = table.to_arrow().to_pandas()\n",
    "        \n",
    "        if df.empty:\n",
    "            return {\n",
    "                'total_chunks': 0,\n",
    "                'unique_documents': 0,\n",
    "                'sources': [],\n",
    "                'chunks_per_source': {},\n",
    "                'avg_chunk_length': 0\n",
    "            }\n",
    "        \n",
    "        sources = df['source'].unique()\n",
    "        source_counts = df['source'].value_counts().to_dict()\n",
    "        \n",
    "        return {\n",
    "            'total_chunks': len(df),\n",
    "            'unique_documents': len(sources),\n",
    "            'sources': sources.tolist(),\n",
    "            'chunks_per_source': source_counts,\n",
    "            'avg_chunk_length': df['text'].str.len().mean()\n",
    "        }\n",
    "    \n",
    "    def semantic_search(self, \n",
    "                       query: str, \n",
    "                       table_name: str = 'documents',\n",
    "                       k: Optional[int] = None,\n",
    "                       threshold: Optional[float] = None,\n",
    "                       source_filter: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"Enhanced semantic search with filtering options.\"\"\"\n",
    "        k = k or self.config.top_k\n",
    "        query_embedding = self.model.encode([query])[0]\n",
    "        table = self.db.open_table(table_name)\n",
    "        \n",
    "        # Build search query\n",
    "        search_query = table.search(query_embedding)\n",
    "        \n",
    "        # Apply source filter if provided\n",
    "        if source_filter:\n",
    "            # Properly format the list for the SQL-like query\n",
    "            formatted_sources = \"(\" + \", \".join([f\"'{s}'\" for s in source_filter]) + \")\"\n",
    "            search_query = search_query.where(f\"source IN {formatted_sources}\")\n",
    "        \n",
    "        # Execute the search and convert to Pandas DataFrame\n",
    "        results_arrow = search_query.limit(k).to_arrow()\n",
    "        \n",
    "        # Convert to Pandas DataFrame\n",
    "        results = results_arrow.to_pandas()\n",
    "        \n",
    "        # Debug: Print available columns\n",
    "        print(\"Available columns in search results:\", results.columns.tolist())\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            logger.warning(\"No results found matching the criteria\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Compute cosine similarity manually\n",
    "        # Ensure 'vector' column exists and contains embeddings\n",
    "        if 'vector' not in results.columns:\n",
    "            logger.error(\"No 'vector' column found in the search results.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        db_embeddings = np.array(results['vector'].tolist())\n",
    "        query_embedding_np = np.array(query_embedding).reshape(1, -1)\n",
    "        similarities = cosine_similarity(db_embeddings, query_embedding_np).flatten()\n",
    "        \n",
    "        # Add similarity scores to the DataFrame\n",
    "        results['similarity'] = similarities\n",
    "        \n",
    "        # Apply similarity threshold if provided\n",
    "        if threshold is not None:\n",
    "            results = results[results['similarity'] >= threshold]\n",
    "            if results.empty:\n",
    "                logger.warning(\"No results meet the similarity threshold.\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        # Sort results by similarity in descending order\n",
    "        results = results.sort_values('similarity', ascending=False)\n",
    "        \n",
    "        # Select and rename relevant columns\n",
    "        return results[['text', 'source', 'similarity']]\n",
    "    \n",
    "    def batch_search(self, \n",
    "                    queries: List[str], \n",
    "                    table_name: str = 'documents',\n",
    "                    k: Optional[int] = None) -> List[pd.DataFrame]:\n",
    "        \"\"\"Perform batch semantic search for multiple queries.\"\"\"\n",
    "        k = k or self.config.top_k\n",
    "        \n",
    "        # Batch encode queries\n",
    "        query_embeddings = self.model.encode(queries, show_progress_bar=True)\n",
    "        \n",
    "        results = []\n",
    "        table = self.db.open_table(table_name)\n",
    "        \n",
    "        for query, embedding in zip(queries, query_embeddings):\n",
    "            search_query = table.search(embedding).limit(k)\n",
    "            results_arrow = search_query.to_arrow()\n",
    "            df = results_arrow.to_pandas()\n",
    "            \n",
    "            if df.empty:\n",
    "                logger.warning(f\"No results found for query: {query}\")\n",
    "                results.append(pd.DataFrame())\n",
    "                continue\n",
    "            \n",
    "            # Compute cosine similarity manually\n",
    "            if 'vector' not in df.columns:\n",
    "                logger.error(f\"No 'vector' column found in search results for query: {query}\")\n",
    "                results.append(pd.DataFrame())\n",
    "                continue\n",
    "            \n",
    "            db_embeddings = np.array(df['vector'].tolist())\n",
    "            embedding_np = np.array(embedding).reshape(1, -1)\n",
    "            similarities = cosine_similarity(db_embeddings, embedding_np).flatten()\n",
    "            \n",
    "            # Add similarity scores to the DataFrame\n",
    "            df['similarity'] = similarities\n",
    "            \n",
    "            # Sort by similarity in descending order\n",
    "            df = df.sort_values('similarity', ascending=False)\n",
    "            \n",
    "            # Add the query to the results\n",
    "            df['query'] = query\n",
    "            results.append(df[['query', 'text', 'source', 'similarity']])\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def delete_table(self, table_name: str) -> None:\n",
    "        \"\"\"Delete a table from the database.\"\"\"\n",
    "        if table_name in self.list_tables():\n",
    "            self.db.drop_table(table_name)\n",
    "            logger.info(f\"Table '{table_name}' deleted\")\n",
    "        else:\n",
    "            logger.warning(f\"Table '{table_name}' not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use the enhanced RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = RAGConfig(\n",
    "#     embedding_model=\"BAAI/bge-small-en-v1.5\",  # Change model if desired\n",
    "#     chunk_size=300,  # Adjust chunk size\n",
    "#     chunk_overlap=30,  # Adjust overlap\n",
    "#     top_k=5  # Adjust number of results\n",
    "# )\n",
    "# # Initialize vector database\n",
    "# db = VectorDB(config)\n",
    "\n",
    "# # Delete the existing table\n",
    "# db.delete_table('documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Documents path: vector_store/documents\n",
      "Database path: vector_store/db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing vector_store/documents/ssrn-3480294.pdf...\n",
      "INFO:__main__:Loading cached processing for vector_store/documents/ssrn-3480294.pdf\n",
      "INFO:__main__:Created new table with 50 chunks\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize system with custom configuration if needed\n",
    "config = RAGConfig(\n",
    "    embedding_model=\"BAAI/bge-small-en-v1.5\",  # Change model if desired\n",
    "    chunk_size=300,  # Adjust chunk size\n",
    "    chunk_overlap=30,  # Adjust overlap\n",
    "    top_k=5  # Adjust number of results\n",
    ")\n",
    "\n",
    "# Initialize processor and process documents\n",
    "processor = DocumentProcessor(config)\n",
    "processor.process_directory()\n",
    "\n",
    "# Initialize vector database\n",
    "db = VectorDB(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available tables:\n",
      "\n",
      "Table: documents\n",
      "Total chunks: 50\n",
      "Unique documents: 1\n",
      "Average chunk length: 1922 characters\n"
     ]
    }
   ],
   "source": [
    "# Get database information\n",
    "print(\"\\nAvailable tables:\")\n",
    "for table_name in db.list_tables():\n",
    "    info = db.get_table_info(table_name)\n",
    "    print(f\"\\nTable: {table_name}\")\n",
    "    print(f\"Total chunks: {info['total_chunks']}\")\n",
    "    print(f\"Unique documents: {info['unique_documents']}\")\n",
    "    print(f\"Average chunk length: {info['avg_chunk_length']:.0f} characters\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8130fe93e38c496c82162f17822b189b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in search results: ['text', 'vector', 'source', 'file_hash', '_distance']\n",
      "\n",
      "Query: the policy question\n",
      "of interest depends on only one, or a very few, price eﬀects.\n",
      "\n",
      "Score: 0.2247\n",
      "Source: vector_store/documents/ssrn-3480294.pdf\n",
      "Text: econometric approach. To elaborate on the economics suppose only one price is\n",
      "varying. For simplicity we consider quantity rather than share. Let ( )b\n",
      "et h ed e m a n df u n c t i o nf o rt h eg o o dw i t hp r i c ev a r y i n g\n",
      "(holding all other prices constant) for one type of individual preferences. Let\n",
      "()be the equivalent variation EV for a price change from to 1for\n",
      "typeHausman and Newey (2016) showed that if the income e ﬀect for every is\n",
      "bounded below and above by andrespectively then Z1 ( )e x p\n",
      "(−[−])≤()≤Z1 ( )e x p (−[−]) If( )is zero over\n",
      "[1]then upper and lower bounds coincide at zero. Itegrating over the\n",
      "distribution of gives Z1 ¯()e x p (−[−])≤¯()≤Z1 ¯()e x p\n",
      "(−[−]) where ¯()=R( )()is average demand. Here ¯()includes\n",
      "the zero surplus in- dividuals as it must do to be an average surplus over all\n",
      "individuals. Also the average overquantities ¯()includes the zeros, as it\n",
      "must do to include in the average surplus those who do not purchase any of the\n",
      "good. Thus we get correct bounds for average EV by including thezeros in\n",
      "estimation of average demand. It also follows from Battacharya (2015) that a\n",
      "veraging over zeros leads to the correct cal- culation in multinomial discrete\n",
      "choice when the price of one good is changing. Let ¯() denote choice\n",
      "probability for the good with changing price. Bhattacharya (2015) shows\n",
      "averageequivalent variation is ¯()=Z 1 ¯() As usual the choice\n",
      "probability is the average across individuals of the choice of 0or1Thus the\n",
      "choice probability is an average demand that includes zeros. Average surplus\n",
      "also includeszeros. Thus we get correct average EV by including zeros. We also\n",
      "note that we\n",
      "\n",
      "Score: 0.2122\n",
      "Source: vector_store/documents/ssrn-3480294.pdf\n",
      "Text: our results are not a ﬀected by having diﬀerent number of observations for di\n",
      "ﬀerent individuals. Assumption 4 given below implicitly includes this condition.\n",
      "Our conditions are like Wooldridge (2018). Also, Hausman and Leibtag (2007)\n",
      "tested the missing at random assumption and found it was not rejected. For panel\n",
      "data we assume that the budget share of individual in time period is\n",
      "=()(=1;=1 ) wheredenotes period speci ﬁc\n",
      "preferences. Here each individual is allowed to have diﬀ erent preferences in\n",
      "each time period. Such idiosy ncratic preference variation should help ﬁtd a t a\n",
      "better because it is often found that individuals make di ﬀerent choices when\n",
      "faced with the same choice sets. If preferences of individuals change over time\n",
      "in unrestricted ways then paneldata provides no more information than cross-\n",
      "section data. Panel data does provide informationwhen time variation is\n",
      "restricted. We will consider individual preferences where the distributionof\n",
      "given=(0 10 )0is the same in each time period. This assumption\n",
      "can be thought of 14 as time homogeneity of preferences, with the pre ference\n",
      "being drawn from the same distribution in each time period conditional on\n",
      "Time homogeneity of preferences corresponds to time homogeneity of\n",
      "disturbances, an econometric condition that has proven useful in recent work on\n",
      "nonlinear panel data models, such as Chernozhukov et al. (2013), Graham and\n",
      "Powell (2012),Hoderlein and White (2011), Chernozhukov et al. (2015), and\n",
      "Chernozhukov, Fernandez-Val,and Newey (2017). Here time homogeneity will allow\n",
      "us to identify the average share, as neededfor BCS, under conditions that we\n",
      "will describe. We will impose the condition that the share is a linear\n",
      "combination of known functions of   Speci ﬁcally, we assume that there is a\n",
      "known vector of functions ()that includes a constant andare coeﬃcients,\n",
      "with individual shares given by =()=()0 As discussed in\n",
      "Hausman and\n",
      "\n",
      "Score: 0.2027\n",
      "Source: vector_store/documents/ssrn-3480294.pdf\n",
      "Text: using a control variable such that preferences are independent of prices,\n",
      "total expenditure, and covariates conditional on , similarly to Hausman and\n",
      "Newey (2016). Another methodological contribution is to treat the “zero problem”\n",
      "of demand estimation as a demand choice, not as a result of a stochastic\n",
      "disturbance. For example, consumer data whichconsiders alcohol or tobacco\n",
      "consumption will have many individuals with zero consumption.In typical demand\n",
      "estimation, where identical parameters are assumed across individuals,\n",
      "zeroconsumption must occur because of a stochastic disturbance, since similar\n",
      "individuals bothconsume and do not consume the same good, e.g. alcohol. However,\n",
      "with a vector of disturbances  of unknown dimension, we allow zero purchases\n",
      "to be the outcome of a demand choice rather than the outcome of a stochastic\n",
      "disturbance. Thus, some consumers have preferences such that they will not\n",
      "consume alcohol or tobacco. A llowing for preference variation and including the\n",
      "zeros in the demand estimation is the correct econometric approach for\n",
      "estimating averagedemand. Similarly, including the zero-consumption outcomes in\n",
      "the estimate of CS and BCS isthe correct approach for policy analysis. This\n",
      "approach to zero consumption outcomes greatlysimpliﬁ es the analysis and\n",
      "estimation of demand systems. An additional contribution is to use panel dat a\n",
      "to control for prices and total expenditure that may be correlated with\n",
      "preferences. Such correlation could result from consumers withhigher\n",
      "elasticities searching more intensively for lower prices. We estimate separate\n",
      "own priceand income e ﬀects for each individual and then average them to obtain\n",
      "average price e ﬀects. We regularize using ridge regression for each individual\n",
      "and debias to correct for ridge regularization on average. The resulting average\n",
      "slope estimators are unbiased if individual coe ﬃcients are independent of\n",
      "regressors and otherwise are a weighted average of individual coe ﬃcients with\n",
      "more strongly identi ﬁed individual coe ﬃcients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example semantic search\n",
    "query = '''the policy question\n",
    "of interest depends on only one, or a very few, price eﬀects.'''\n",
    "results = db.semantic_search(\n",
    "    query=query,\n",
    "    k=3,  # Number of results\n",
    "    threshold=0.2,  # Optional similarity threshold\n",
    "    source_filter=None  # Optional source filtering\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {query}\\n\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"Score: {row['similarity']:.4f}\")\n",
    "    print(f\"Source: {row['source']}\")\n",
    "    print(f\"Text: {textwrap.fill(row['text'], width=80)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ba51c346e6432598d010dd1e888a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for query: query 1\n",
      "Score: 0.1608\n",
      "Text: the use of grocery store scanner data, allowance for nonparametric, general\n",
      "heterogeneity in the cross-section, including zeros in regressions, and in the\n",
      "comparison of cross-section and panelresults. 2 Demand and Weighted Average\n",
      "Surplus We consider a demand model where the form of heterogeneity is\n",
      "unrestricted. To describe themodel let denote the quantity of a vector of\n",
      "goods, the quantity of a numeraire good, the price vector for relative to ,a\n",
      "n dthe individual income level relative to the numeraire price. The unobserved\n",
      "heterogeneity will be represented by a vector of unobserved disturbances of\n",
      "unknown dimension. We think of each value of as corresponding to a consumer but\n",
      "do allow to be continuously distributed. For each consumer the demand function\n",
      "( )will be obtained by maximizing a utility function( )that is\n",
      "monotonic increasing in andsubject to the budget constraint, with ( ) =\n",
      "arg max ≥0≥0( )s.t.0+≤ (2.1) Here we assume that demand is single\n",
      "valued and not a correspondence. This assumption is essentially equivalent to\n",
      "strict quasi-concavity of the utility function. We impose no form on the way\n",
      "enters the utility function and hence the form of heterogeneity is completely\n",
      "unrestricted. For analyzing the e ﬀect of price changes on welfare we focus on\n",
      "equivalent variation. Let ( )=m i n ≥0≥0{0+s.t.( )≥}be the\n",
      "expenditure function and ()= −(01)be the equivalent variation for\n",
      "individual for a price change from 0to1 with income and1the utility at\n",
      "price 1. The corresponding deadweight loss is ()= ()−(1−0)0(1\n",
      ") I nt h er e m a i n d e ro ft h i sp a p e rw ef o c u so nt h ec a s ew h e\n",
      "r et h e ﬁrst price1changes from ˇ1 to a higher value ¯1and the other prices\n",
      "2in=(10 2)0areﬁxed. In that case the\n",
      "\n",
      "Score: 0.1560\n",
      "Text: demand for the good as a function of 1andholding all other prices 2and\n",
      "covariates  ﬁxed. Then by local nonsatiation, =X =1(1)−∆=X\n",
      "=1(1−∆) Subtracting the second equation from the ﬁrst gives ∆=X\n",
      "=1[(1)−(1−∆)]≥1[1(1)−1(1−∆)]≥ˇ1[1(1)−1(1−∆)]\n",
      "26 where the ﬁrst inequality follows by all goods being normal goods and the\n",
      "second by 1∈[ˇ1¯1]. Dividing through by ˇ1gives ¯=1ˇ1Also=0follows by\n",
      "1being a normal good. Q.E.D. . The following two results are useful in the\n",
      "proof of Theorem 2. Let  (˜)=(˜)(˜),\n",
      "¯=[(˜)]¯=[()],a n d=¯¯(=1 ) Lemma A1: If\n",
      "Assumption 3 is satis ﬁed then for any two empirical CDF’s ˆand ˜for\n",
      "subsamples with sample sizes greater than for some , max ≤¯¯¯ˆ−¯¯¯=(p\n",
      "ln())Z (˜)ˆ(˜)(ˆ−0)(˜)(˜−0)( )=(−12) Proof: By\n",
      "Assumptions 2 and 3 (˜) (˜),a n d()are each bounded uniformly in\n",
      ",˜, andso that (˜)is also. Then by Assumption 2 and standard maximal\n",
      "inequality arguments, max ≤¯¯¯¯Z  (˜)(ˆ−0)(˜)¯¯¯¯= (r ln() )max\n",
      "≤¯¯¯¯Z  ()(ˆ−0)()¯¯¯¯= (r ln() ) Then we have ¯¯¯ˆ−¯¯¯≤¯¯¯¯Z\n",
      " (˜)(ˆ−0)(˜)¯¯¯¯¯¯¯¯Z  ()(ˆ−0)( )¯¯¯¯ +¯¯¯¯Z \n",
      "(˜)(ˆ−0)(˜)¯¯¯¯¯¯¯ ¯¯+¯¯¯ ¯¯¯¯¯¯Z  ()(ˆ−0)( )¯¯¯¯ so the\n",
      "ﬁrst conclusion follows by¯¯¯ ¯¯and¯¯¯ ¯¯uniformly bounded in .A l s o b\n",
      "y L e m m a A 3 o f Chernozhukov, Newey, and Singh (2018),P\n",
      "=1¯¯¯ˆ¯¯¯=¯¯¯ˆ¯¯¯ 1=(1)Then by Assumptions 2 and 3 it follows that ¯¯¯¯Z\n",
      "()ˆ()(ˆ− 0)( )(˜−0)( )¯¯¯¯=¯¯¯¯¯X =1ˆ[Z  ()(ˆ−0)( )][Z\n",
      "()(˜−0)( )]¯¯¯¯¯ ≤¯¯¯ˆ¯¯¯ 1max ≤¯¯¯¯Z  (˜)(ˆ−0)(˜)¯¯¯¯max\n",
      "≤¯¯¯¯Z  ()(˜−0)()¯¯¯¯=(ln( ) )=(−12) P r o o fo fT h e\n",
      "o r e m2 : Weﬁxand let ˆbe the empirical distribution over observations not\n",
      "inand ˜be the empirical distribution over observations in Also de\n",
      "ﬁne0(˜)= (˜)0(˜)ˆ(˜)=(˜)ˆ(˜) 1=Z ˆ(˜)³ ˆ−0´ (˜)³\n",
      "ˆ−0´ () 2=Z ˆ(˜)³ ˜−0´ (˜)ˆ()−Z 0(˜)³ ˜−0´ (˜)0()\n",
      "3=Z ˆ(˜)ˆ(˜)³ ˜−0´ ()−Z 0(˜)0(˜)³ ˜−0´ () 27 L e m m aA\n",
      "1i m p l i e st h a t\n",
      "\n",
      "Score: 0.1426\n",
      "Text: using a control variable such that preferences are independent of prices,\n",
      "total expenditure, and covariates conditional on , similarly to Hausman and\n",
      "Newey (2016). Another methodological contribution is to treat the “zero problem”\n",
      "of demand estimation as a demand choice, not as a result of a stochastic\n",
      "disturbance. For example, consumer data whichconsiders alcohol or tobacco\n",
      "consumption will have many individuals with zero consumption.In typical demand\n",
      "estimation, where identical parameters are assumed across individuals,\n",
      "zeroconsumption must occur because of a stochastic disturbance, since similar\n",
      "individuals bothconsume and do not consume the same good, e.g. alcohol. However,\n",
      "with a vector of disturbances  of unknown dimension, we allow zero purchases\n",
      "to be the outcome of a demand choice rather than the outcome of a stochastic\n",
      "disturbance. Thus, some consumers have preferences such that they will not\n",
      "consume alcohol or tobacco. A llowing for preference variation and including the\n",
      "zeros in the demand estimation is the correct econometric approach for\n",
      "estimating averagedemand. Similarly, including the zero-consumption outcomes in\n",
      "the estimate of CS and BCS isthe correct approach for policy analysis. This\n",
      "approach to zero consumption outcomes greatlysimpliﬁ es the analysis and\n",
      "estimation of demand systems. An additional contribution is to use panel dat a\n",
      "to control for prices and total expenditure that may be correlated with\n",
      "preferences. Such correlation could result from consumers withhigher\n",
      "elasticities searching more intensively for lower prices. We estimate separate\n",
      "own priceand income e ﬀects for each individual and then average them to obtain\n",
      "average price e ﬀects. We regularize using ridge regression for each individual\n",
      "and debias to correct for ridge regularization on average. The resulting average\n",
      "slope estimators are unbiased if individual coe ﬃcients are independent of\n",
      "regressors and otherwise are a weighted average of individual coe ﬃcients with\n",
      "more strongly identi ﬁed individual coe ﬃcients\n",
      "\n",
      "Score: 0.1334\n",
      "Text: allowance for general, nonparametric heterogeneity facilitates this solution to\n",
      "the zeros problem. We allow for many prices by using debiased machine learning\n",
      "inthe cross-section and bias corrected ridge regular ization for panel data. The\n",
      "cross-section allows endogeneity of total expenditure and potentially of prices\n",
      "via inclusion of control functions. Inthese ways we provide useful approaches to\n",
      "estimation of demand models in large data sets withmany prices, where prices may\n",
      "be correlated with preferences. 7 Appendix A: Assumptions A1 and A2. I nt h i sb\n",
      "r i e fA p p e n d i xw eg i v eA s s u m p t i o n sA 1a n dA 2w h i c ha r eu\n",
      "s e di nt h er e s u l tf o rt h eD M Lestimator of Section 3. We give only a\n",
      "brief discussion here. A more extensive discussion canbe found in Chernozhukov,\n",
      "Newey, and Singh (2018). Assumption A1 gives an approximationrate hypothesis for\n",
      "both the regression  0()and the Riesz representer 0() Assumption A1:\n",
      "There exists  0¯,a n d ¯with ¯nonzero elements such thatP\n",
      "=1|¯|≤P=1¯¯¯¯¯≤andk 0−0¯k2≤p ln( )°° 0−0¯°°2≤¯ln()\n",
      "The next Assumption gives a sparse eigenval ue conditions that is common in the\n",
      "Lasso literature Assumption A2: =[()()0]is nonsingular and has largest\n",
      "eigenvalue uniformly bounded in .Also there is  3such that for ˜=a r gm i n©\n",
      "k0−0k2+||1ª andJ={: ˜6=0} inf {:6=0 ∈J||≤ ∈J||}0P\n",
      "∈J2 0 8 Appendix B: Proofs of Theorems P r o o fo fL e m m a1 : In this\n",
      "proof let denote the number of goods and (1)denote the demand for the\n",
      "good as a function of 1andholding all other prices 2and covariates  ﬁxed.\n",
      "Then by local nonsatiation, =X =1(1)−∆=X =1(1−∆)\n",
      "Subtracting the second equation from the ﬁrst\n",
      "\n",
      "Score: 0.1301\n",
      "Text: Vol. II , Cambridge: Cambridge University Press. Blundell, R., D. Kristensen,\n",
      "and R. Matzkin (2014): \"Bounding Quantile Demand Functions Using Revealed\n",
      "Preference Inequalities,\" Journal of Econometrics 179, 112—127. Blundell, R. and\n",
      "R. Matzkin (2014): \"Control Functions in Nonseparable Simultaneous Equations\n",
      "Models,\" Quantitative Economics 5, 271—295. Burda, M., M. Harding, J.A. Hausman\n",
      "(2008): \"A Bayesian Mixed Logit Probit model for Multinomial Choice,\" Journal of\n",
      "Econometrics 147, 232-246. Burda, M., M. Harding, J.A. Hausman (2012): \"A\n",
      "Poisson Mixture Model of Discrete Choice,\" Journal of Econometrics 166, 184-203.\n",
      "Burtless, G. and J.A. Hausman (1978): \"The E ﬀect of Taxation on Labor Supply:\n",
      "Evaluating t h eG a r yN e g a t i v eI n c o m eT a xE x p e r i m e n t s ,\n",
      "\"Journal of Political Economy 86, 1103-1130. Chamberlain, G. (1982):\n",
      "\"Multivariate Regression Models for Panel Data,\" Journal of Econometrics 18,\n",
      "5-46. Chamberlain, G. (1984): \"Panel Data,\" in Handbook of Econometrics, Volume\n",
      "2 ,e d s . Z . Griliches and M. Intriligator,Amsterdam: North-Holland, 1984,\n",
      "1247—1318. 35 Chamberlain, G. (1992): \"E ﬃciency Bounds for Semiparametric\n",
      "Regression,\" Econometrica 60, 567-596. Chernozhukov, V., I. Fernandez-Val, J.\n",
      "Hahn, W. Newey (2013): \"Average and Quantile Eﬀects in Nonseparable Panel\n",
      "Models,\" Econometrica 81, 535—580. Chernozhukov, V., I. Fernandez-Val, S. Hode\n",
      "rlein, H. Holzmann, and W.K. Newey (2015): \"Quantile Derivatives and Panel\n",
      "Data,\" Journal of Econometrics 188, 378-392. Chernozhukov, V., I. Fernandez-Val,\n",
      "and W.K. Newey (2017): \"Nonseparable Multinomial Choice Models in Cross-Section\n",
      "and Panel Data,” Journal of Econometrics, forthcoming. Chernozhukov, V., W.K.\n",
      "Newey, and J. Robins (2018): \"Double/De-Biased Machine Learn- ing Using\n",
      "Regularized Riesz Representers,\" https://arxiv.org/abs/1802.08667. Chernozhukov,\n",
      "V., W.K. Newey, and R. Singh (2018): \"Learning L2-Continuous Regression\n",
      "Functionals via Regularized Riesz Represent ers,\"\n",
      "https://arxiv.org/pdf/1809.05224. Deaton, A. and J. Muellbauer (1980):\n",
      "\"Economics of Consumer Behavior,\" Cambridge: Cambridge University\n",
      "\n",
      "\n",
      "Results for query: query 2\n",
      "Score: 0.1847\n",
      "Text: the use of grocery store scanner data, allowance for nonparametric, general\n",
      "heterogeneity in the cross-section, including zeros in regressions, and in the\n",
      "comparison of cross-section and panelresults. 2 Demand and Weighted Average\n",
      "Surplus We consider a demand model where the form of heterogeneity is\n",
      "unrestricted. To describe themodel let denote the quantity of a vector of\n",
      "goods, the quantity of a numeraire good, the price vector for relative to ,a\n",
      "n dthe individual income level relative to the numeraire price. The unobserved\n",
      "heterogeneity will be represented by a vector of unobserved disturbances of\n",
      "unknown dimension. We think of each value of as corresponding to a consumer but\n",
      "do allow to be continuously distributed. For each consumer the demand function\n",
      "( )will be obtained by maximizing a utility function( )that is\n",
      "monotonic increasing in andsubject to the budget constraint, with ( ) =\n",
      "arg max ≥0≥0( )s.t.0+≤ (2.1) Here we assume that demand is single\n",
      "valued and not a correspondence. This assumption is essentially equivalent to\n",
      "strict quasi-concavity of the utility function. We impose no form on the way\n",
      "enters the utility function and hence the form of heterogeneity is completely\n",
      "unrestricted. For analyzing the e ﬀect of price changes on welfare we focus on\n",
      "equivalent variation. Let ( )=m i n ≥0≥0{0+s.t.( )≥}be the\n",
      "expenditure function and ()= −(01)be the equivalent variation for\n",
      "individual for a price change from 0to1 with income and1the utility at\n",
      "price 1. The corresponding deadweight loss is ()= ()−(1−0)0(1\n",
      ") I nt h er e m a i n d e ro ft h i sp a p e rw ef o c u so nt h ec a s ew h e\n",
      "r et h e ﬁrst price1changes from ˇ1 to a higher value ¯1and the other prices\n",
      "2in=(10 2)0areﬁxed. In that case the\n",
      "\n",
      "Score: 0.1517\n",
      "Text: using a control variable such that preferences are independent of prices,\n",
      "total expenditure, and covariates conditional on , similarly to Hausman and\n",
      "Newey (2016). Another methodological contribution is to treat the “zero problem”\n",
      "of demand estimation as a demand choice, not as a result of a stochastic\n",
      "disturbance. For example, consumer data whichconsiders alcohol or tobacco\n",
      "consumption will have many individuals with zero consumption.In typical demand\n",
      "estimation, where identical parameters are assumed across individuals,\n",
      "zeroconsumption must occur because of a stochastic disturbance, since similar\n",
      "individuals bothconsume and do not consume the same good, e.g. alcohol. However,\n",
      "with a vector of disturbances  of unknown dimension, we allow zero purchases\n",
      "to be the outcome of a demand choice rather than the outcome of a stochastic\n",
      "disturbance. Thus, some consumers have preferences such that they will not\n",
      "consume alcohol or tobacco. A llowing for preference variation and including the\n",
      "zeros in the demand estimation is the correct econometric approach for\n",
      "estimating averagedemand. Similarly, including the zero-consumption outcomes in\n",
      "the estimate of CS and BCS isthe correct approach for policy analysis. This\n",
      "approach to zero consumption outcomes greatlysimpliﬁ es the analysis and\n",
      "estimation of demand systems. An additional contribution is to use panel dat a\n",
      "to control for prices and total expenditure that may be correlated with\n",
      "preferences. Such correlation could result from consumers withhigher\n",
      "elasticities searching more intensively for lower prices. We estimate separate\n",
      "own priceand income e ﬀects for each individual and then average them to obtain\n",
      "average price e ﬀects. We regularize using ridge regression for each individual\n",
      "and debias to correct for ridge regularization on average. The resulting average\n",
      "slope estimators are unbiased if individual coe ﬃcients are independent of\n",
      "regressors and otherwise are a weighted average of individual coe ﬃcients with\n",
      "more strongly identi ﬁed individual coe ﬃcients\n",
      "\n",
      "Score: 0.1391\n",
      "Text: a plug-in estimator can have large bias. We debias by adding the inﬂuence\n",
      "adjustment that corrects for the presence of an unknown conditional expectation\n",
      "and 11 marginal distribution. The adjustment is the in ﬂuence function\n",
      "ofRR(˜)(˜ )0(˜)() where( )denotes the conditional\n",
      "expectation of given ()andthe marginal dis- tribution of whenis the true\n",
      "distribution. As in Newey (1994, p. 1357) the in ﬂuence adjustment will be the\n",
      "sum of two terms, one being the adjustment for and the other for . The in\n",
      "ﬂuence adjustment for depends on a Riesz representer 0()such that [Z\n",
      "(˜)(˜)()] =[0()()] 0()=()20(2)0()\n",
      "0() for all()with ﬁnite second moment, where 20()and0()are\n",
      "the marginal pdf’s of 2andand0()the joint pdf. The adjustment for is\n",
      "1( )=()[−()] whereandrepresent a possible conditional mean and\n",
      "Riesz representer, as shown by Newey (1994). Also, the adjustment for is\n",
      "2( ˜)=Z (˜)(˜)˜(˜)−ZZ (˜)(˜)˜(˜)()]\n",
      "where˜anda r ep o s s i b l eC D F ’ so f ˜andrespectively, as shown in\n",
      "Newey and McFadden (1994). Plugging in estimators ˆand ˆand taking ˆand\n",
      "ˆ˜to be the empirical distributions over observations not in gives the\n",
      "estimated adjustment term ˆ()= ˆ1()+ˆ2()ˆ1()=ˆ()[−ˆ()]\n",
      "ˆ2()=1 −X ∈(˜)ˆ(˜)−µ1 −¶2X 0∈(˜)ˆ(˜0) The\n",
      "DML estimator with cross- ﬁtting for the in ﬂuence adjustment is then ˆ=˜+1\n",
      "X =1X ∈ˆ() This estimator depends on the estimator ˆof the Riesz\n",
      "representer 0It is not necessary to use the form of 0to estimate it. We can\n",
      "construct a Lasso minimum distance estimator that automatically estimates\n",
      "0using only (˜)without knowing the form of 0Let ˆdenote a ×1vector with\n",
      "component ˆ=µ1 −¶2X ∈X ∈(˜)(˜)(=1 )ˆ=1\n",
      "−X ∈()()0 The estimator ˆis ˆ()=()0ˆˆ=a r\n",
      "gm i n {−2ˆ0 +0ˆ+X =1||} 12 The coeﬃcients ˆminimize a\n",
      "1penalized minimum distance objective function. The ˆhere has a novel form in\n",
      "accounting for endogeneity through averaging over the control function. The\n",
      "objective function\n",
      "\n",
      "Score: 0.1357\n",
      "Text: demand for the good as a function of 1andholding all other prices 2and\n",
      "covariates  ﬁxed. Then by local nonsatiation, =X =1(1)−∆=X\n",
      "=1(1−∆) Subtracting the second equation from the ﬁrst gives ∆=X\n",
      "=1[(1)−(1−∆)]≥1[1(1)−1(1−∆)]≥ˇ1[1(1)−1(1−∆)]\n",
      "26 where the ﬁrst inequality follows by all goods being normal goods and the\n",
      "second by 1∈[ˇ1¯1]. Dividing through by ˇ1gives ¯=1ˇ1Also=0follows by\n",
      "1being a normal good. Q.E.D. . The following two results are useful in the\n",
      "proof of Theorem 2. Let  (˜)=(˜)(˜),\n",
      "¯=[(˜)]¯=[()],a n d=¯¯(=1 ) Lemma A1: If\n",
      "Assumption 3 is satis ﬁed then for any two empirical CDF’s ˆand ˜for\n",
      "subsamples with sample sizes greater than for some , max ≤¯¯¯ˆ−¯¯¯=(p\n",
      "ln())Z (˜)ˆ(˜)(ˆ−0)(˜)(˜−0)( )=(−12) Proof: By\n",
      "Assumptions 2 and 3 (˜) (˜),a n d()are each bounded uniformly in\n",
      ",˜, andso that (˜)is also. Then by Assumption 2 and standard maximal\n",
      "inequality arguments, max ≤¯¯¯¯Z  (˜)(ˆ−0)(˜)¯¯¯¯= (r ln() )max\n",
      "≤¯¯¯¯Z  ()(ˆ−0)()¯¯¯¯= (r ln() ) Then we have ¯¯¯ˆ−¯¯¯≤¯¯¯¯Z\n",
      " (˜)(ˆ−0)(˜)¯¯¯¯¯¯¯¯Z  ()(ˆ−0)( )¯¯¯¯ +¯¯¯¯Z \n",
      "(˜)(ˆ−0)(˜)¯¯¯¯¯¯¯ ¯¯+¯¯¯ ¯¯¯¯¯¯Z  ()(ˆ−0)( )¯¯¯¯ so the\n",
      "ﬁrst conclusion follows by¯¯¯ ¯¯and¯¯¯ ¯¯uniformly bounded in .A l s o b\n",
      "y L e m m a A 3 o f Chernozhukov, Newey, and Singh (2018),P\n",
      "=1¯¯¯ˆ¯¯¯=¯¯¯ˆ¯¯¯ 1=(1)Then by Assumptions 2 and 3 it follows that ¯¯¯¯Z\n",
      "()ˆ()(ˆ− 0)( )(˜−0)( )¯¯¯¯=¯¯¯¯¯X =1ˆ[Z  ()(ˆ−0)( )][Z\n",
      "()(˜−0)( )]¯¯¯¯¯ ≤¯¯¯ˆ¯¯¯ 1max ≤¯¯¯¯Z  (˜)(ˆ−0)(˜)¯¯¯¯max\n",
      "≤¯¯¯¯Z  ()(˜−0)()¯¯¯¯=(ln( ) )=(−12) P r o o fo fT h e\n",
      "o r e m2 : Weﬁxand let ˆbe the empirical distribution over observations not\n",
      "inand ˜be the empirical distribution over observations in Also de\n",
      "ﬁne0(˜)= (˜)0(˜)ˆ(˜)=(˜)ˆ(˜) 1=Z ˆ(˜)³ ˆ−0´ (˜)³\n",
      "ˆ−0´ () 2=Z ˆ(˜)³ ˜−0´ (˜)ˆ()−Z 0(˜)³ ˜−0´ (˜)0()\n",
      "3=Z ˆ(˜)ˆ(˜)³ ˜−0´ ()−Z 0(˜)0(˜)³ ˜−0´ () 27 L e m m aA\n",
      "1i m p l i e st h a t\n",
      "\n",
      "Score: 0.1262\n",
      "Text: allowance for general, nonparametric heterogeneity facilitates this solution to\n",
      "the zeros problem. We allow for many prices by using debiased machine learning\n",
      "inthe cross-section and bias corrected ridge regular ization for panel data. The\n",
      "cross-section allows endogeneity of total expenditure and potentially of prices\n",
      "via inclusion of control functions. Inthese ways we provide useful approaches to\n",
      "estimation of demand models in large data sets withmany prices, where prices may\n",
      "be correlated with preferences. 7 Appendix A: Assumptions A1 and A2. I nt h i sb\n",
      "r i e fA p p e n d i xw eg i v eA s s u m p t i o n sA 1a n dA 2w h i c ha r eu\n",
      "s e di nt h er e s u l tf o rt h eD M Lestimator of Section 3. We give only a\n",
      "brief discussion here. A more extensive discussion canbe found in Chernozhukov,\n",
      "Newey, and Singh (2018). Assumption A1 gives an approximationrate hypothesis for\n",
      "both the regression  0()and the Riesz representer 0() Assumption A1:\n",
      "There exists  0¯,a n d ¯with ¯nonzero elements such thatP\n",
      "=1|¯|≤P=1¯¯¯¯¯≤andk 0−0¯k2≤p ln( )°° 0−0¯°°2≤¯ln()\n",
      "The next Assumption gives a sparse eigenval ue conditions that is common in the\n",
      "Lasso literature Assumption A2: =[()()0]is nonsingular and has largest\n",
      "eigenvalue uniformly bounded in .Also there is  3such that for ˜=a r gm i n©\n",
      "k0−0k2+||1ª andJ={: ˜6=0} inf {:6=0 ∈J||≤ ∈J||}0P\n",
      "∈J2 0 8 Appendix B: Proofs of Theorems P r o o fo fL e m m a1 : In this\n",
      "proof let denote the number of goods and (1)denote the demand for the\n",
      "good as a function of 1andholding all other prices 2and covariates  ﬁxed.\n",
      "Then by local nonsatiation, =X =1(1)−∆=X =1(1−∆)\n",
      "Subtracting the second equation from the ﬁrst\n",
      "\n",
      "\n",
      "Results for query: query 3\n",
      "Score: 0.1151\n",
      "Text: the use of grocery store scanner data, allowance for nonparametric, general\n",
      "heterogeneity in the cross-section, including zeros in regressions, and in the\n",
      "comparison of cross-section and panelresults. 2 Demand and Weighted Average\n",
      "Surplus We consider a demand model where the form of heterogeneity is\n",
      "unrestricted. To describe themodel let denote the quantity of a vector of\n",
      "goods, the quantity of a numeraire good, the price vector for relative to ,a\n",
      "n dthe individual income level relative to the numeraire price. The unobserved\n",
      "heterogeneity will be represented by a vector of unobserved disturbances of\n",
      "unknown dimension. We think of each value of as corresponding to a consumer but\n",
      "do allow to be continuously distributed. For each consumer the demand function\n",
      "( )will be obtained by maximizing a utility function( )that is\n",
      "monotonic increasing in andsubject to the budget constraint, with ( ) =\n",
      "arg max ≥0≥0( )s.t.0+≤ (2.1) Here we assume that demand is single\n",
      "valued and not a correspondence. This assumption is essentially equivalent to\n",
      "strict quasi-concavity of the utility function. We impose no form on the way\n",
      "enters the utility function and hence the form of heterogeneity is completely\n",
      "unrestricted. For analyzing the e ﬀect of price changes on welfare we focus on\n",
      "equivalent variation. Let ( )=m i n ≥0≥0{0+s.t.( )≥}be the\n",
      "expenditure function and ()= −(01)be the equivalent variation for\n",
      "individual for a price change from 0to1 with income and1the utility at\n",
      "price 1. The corresponding deadweight loss is ()= ()−(1−0)0(1\n",
      ") I nt h er e m a i n d e ro ft h i sp a p e rw ef o c u so nt h ec a s ew h e\n",
      "r et h e ﬁrst price1changes from ˇ1 to a higher value ¯1and the other prices\n",
      "2in=(10 2)0areﬁxed. In that case the\n",
      "\n",
      "Score: 0.1121\n",
      "Text: a plug-in estimator can have large bias. We debias by adding the inﬂuence\n",
      "adjustment that corrects for the presence of an unknown conditional expectation\n",
      "and 11 marginal distribution. The adjustment is the in ﬂuence function\n",
      "ofRR(˜)(˜ )0(˜)() where( )denotes the conditional\n",
      "expectation of given ()andthe marginal dis- tribution of whenis the true\n",
      "distribution. As in Newey (1994, p. 1357) the in ﬂuence adjustment will be the\n",
      "sum of two terms, one being the adjustment for and the other for . The in\n",
      "ﬂuence adjustment for depends on a Riesz representer 0()such that [Z\n",
      "(˜)(˜)()] =[0()()] 0()=()20(2)0()\n",
      "0() for all()with ﬁnite second moment, where 20()and0()are\n",
      "the marginal pdf’s of 2andand0()the joint pdf. The adjustment for is\n",
      "1( )=()[−()] whereandrepresent a possible conditional mean and\n",
      "Riesz representer, as shown by Newey (1994). Also, the adjustment for is\n",
      "2( ˜)=Z (˜)(˜)˜(˜)−ZZ (˜)(˜)˜(˜)()]\n",
      "where˜anda r ep o s s i b l eC D F ’ so f ˜andrespectively, as shown in\n",
      "Newey and McFadden (1994). Plugging in estimators ˆand ˆand taking ˆand\n",
      "ˆ˜to be the empirical distributions over observations not in gives the\n",
      "estimated adjustment term ˆ()= ˆ1()+ˆ2()ˆ1()=ˆ()[−ˆ()]\n",
      "ˆ2()=1 −X ∈(˜)ˆ(˜)−µ1 −¶2X 0∈(˜)ˆ(˜0) The\n",
      "DML estimator with cross- ﬁtting for the in ﬂuence adjustment is then ˆ=˜+1\n",
      "X =1X ∈ˆ() This estimator depends on the estimator ˆof the Riesz\n",
      "representer 0It is not necessary to use the form of 0to estimate it. We can\n",
      "construct a Lasso minimum distance estimator that automatically estimates\n",
      "0using only (˜)without knowing the form of 0Let ˆdenote a ×1vector with\n",
      "component ˆ=µ1 −¶2X ∈X ∈(˜)(˜)(=1 )ˆ=1\n",
      "−X ∈()()0 The estimator ˆis ˆ()=()0ˆˆ=a r\n",
      "gm i n {−2ˆ0 +0ˆ+X =1||} 12 The coeﬃcients ˆminimize a\n",
      "1penalized minimum distance objective function. The ˆhere has a novel form in\n",
      "accounting for endogeneity through averaging over the control function. The\n",
      "objective function\n",
      "\n",
      "Score: 0.1046\n",
      "Text: Vol. II , Cambridge: Cambridge University Press. Blundell, R., D. Kristensen,\n",
      "and R. Matzkin (2014): \"Bounding Quantile Demand Functions Using Revealed\n",
      "Preference Inequalities,\" Journal of Econometrics 179, 112—127. Blundell, R. and\n",
      "R. Matzkin (2014): \"Control Functions in Nonseparable Simultaneous Equations\n",
      "Models,\" Quantitative Economics 5, 271—295. Burda, M., M. Harding, J.A. Hausman\n",
      "(2008): \"A Bayesian Mixed Logit Probit model for Multinomial Choice,\" Journal of\n",
      "Econometrics 147, 232-246. Burda, M., M. Harding, J.A. Hausman (2012): \"A\n",
      "Poisson Mixture Model of Discrete Choice,\" Journal of Econometrics 166, 184-203.\n",
      "Burtless, G. and J.A. Hausman (1978): \"The E ﬀect of Taxation on Labor Supply:\n",
      "Evaluating t h eG a r yN e g a t i v eI n c o m eT a xE x p e r i m e n t s ,\n",
      "\"Journal of Political Economy 86, 1103-1130. Chamberlain, G. (1982):\n",
      "\"Multivariate Regression Models for Panel Data,\" Journal of Econometrics 18,\n",
      "5-46. Chamberlain, G. (1984): \"Panel Data,\" in Handbook of Econometrics, Volume\n",
      "2 ,e d s . Z . Griliches and M. Intriligator,Amsterdam: North-Holland, 1984,\n",
      "1247—1318. 35 Chamberlain, G. (1992): \"E ﬃciency Bounds for Semiparametric\n",
      "Regression,\" Econometrica 60, 567-596. Chernozhukov, V., I. Fernandez-Val, J.\n",
      "Hahn, W. Newey (2013): \"Average and Quantile Eﬀects in Nonseparable Panel\n",
      "Models,\" Econometrica 81, 535—580. Chernozhukov, V., I. Fernandez-Val, S. Hode\n",
      "rlein, H. Holzmann, and W.K. Newey (2015): \"Quantile Derivatives and Panel\n",
      "Data,\" Journal of Econometrics 188, 378-392. Chernozhukov, V., I. Fernandez-Val,\n",
      "and W.K. Newey (2017): \"Nonseparable Multinomial Choice Models in Cross-Section\n",
      "and Panel Data,” Journal of Econometrics, forthcoming. Chernozhukov, V., W.K.\n",
      "Newey, and J. Robins (2018): \"Double/De-Biased Machine Learn- ing Using\n",
      "Regularized Riesz Representers,\" https://arxiv.org/abs/1802.08667. Chernozhukov,\n",
      "V., W.K. Newey, and R. Singh (2018): \"Learning L2-Continuous Regression\n",
      "Functionals via Regularized Riesz Represent ers,\"\n",
      "https://arxiv.org/pdf/1809.05224. Deaton, A. and J. Muellbauer (1980):\n",
      "\"Economics of Consumer Behavior,\" Cambridge: Cambridge University\n",
      "\n",
      "Score: 0.0981\n",
      "Text: Prices Victor Chernozhukov, Jerry A. Hausman, and Whitney K. Newey NBER Working\n",
      "Paper No. 26424 November 2019 JEL No. C13,C14,C21,C23,C55,D12 ABSTRACT From its\n",
      "inception, demand estimation has faced the problem of \"many prices.\" This paper\n",
      "provides estimators of average demand and associated bounds on exact consumer\n",
      "surplus when there are many prices in cross-section or panel data. For cross-\n",
      "section data we provide a debiased machine learner of consumer surplus bounds\n",
      "that allows for general heterogeneity and solves the \"zeros problem\" of demand.\n",
      "For panel data we provide bias corrected, ridge regularized estimators of\n",
      "average coefficients and consumer surplus bounds. In scanner data we find\n",
      "smaller panel elasticities than cross-section and that soda price increases are\n",
      "regressive. Victor Chernozhukov Department of Economics Massachusetts Institute\n",
      "of Technology 77 Massachusetts Avenue Cambridge, Mass. 02139 vchern@mit.edu\n",
      "Jerry A. Hausman Department of Economics, E52-518 MIT 50 Memorial Drive\n",
      "Cambridge, MA 02142 and NBER jhausman@mit.eduWhitney K. Newey Department of\n",
      "Economics, E52-424 MIT 50 Memorial Drive Cambridge, MA 02142 and NBER\n",
      "wnewey@mit.edu 1 Introduction Estimation of demand models has a long history in\n",
      "econometrics. Beginning in the 1950s during the “Stone age” of econometrics at\n",
      "Cambridge University and elsewhere, applied researchersbegan estimating systems\n",
      "of demand equations as computer power increased. 1From its incep- tion, demand\n",
      "estimation faced the problem of “many prices.” A demand system of goods for\n",
      "persontakes the form =(),w h e r eis an vector of quantities\n",
      "demanded, is an-vector of prices, is a measure of income or expenditure,\n",
      "is a conditioning variable for the individual and potentially for variables\n",
      "that are time speci ﬁc, andis a vector of unknown dimension (potentially an in\n",
      "ﬁnite vector) of an unobserved heterogeneity term and stochas- tic terms. Since\n",
      "has high dimension, the presence of many goods and many prices creates problems\n",
      "for demand estimation.2 While some\n",
      "\n",
      "Score: 0.0979\n",
      "Text: and Newey (2002) derived the form of average demand with nonparametric,\n",
      "nonseparable, scalar heterogeneity and nonlinear taxes andBlomquist, Kumar,\n",
      "Liang, and Newey (2014) showed the same form for general heterogeneity.Hoderlein\n",
      "and Stoye (2014) showed how to impose the weak axiom of revealed preference.\n",
      "Dette,Hoderlein, and Neumeyer (2016) proposed tests of downward sloping\n",
      "compensated demands. Bhattacharya (2015) derived average surplus for discrete\n",
      "demand and general heterogeneity. Kitamura and Stoye (2018) gave tests of the\n",
      "revealed preference hypothesis. The double machine learning estimator is novel\n",
      "in the use of a minimum distance Lasso method to debias the estimator when using\n",
      "a control variable. The estimator and theory buildon that of Chernozhukov,\n",
      "Newey, and Robins (2018) and Chernozhukov, Newey, and Singh(2018) for minimum\n",
      "distance Lasso bias correction without a control function. This work inturn\n",
      "builds on Belloni et al. (2012) and Belloni, Chernozhukov and Hansen (2013) on\n",
      "debiasedmachine learning. For panel data Chamberlain (1982, 1992), Pesa r a na n\n",
      "dS m i t h( 1 9 9 5 ) , Wooldridge (2005), Arellano and Bonhomme (2012),\n",
      "Chernozhukov, Fernandez-Val, Hahn, and Newey (2013), andGraham and Powell (2012)\n",
      "have considered averaging individual slope estimates. The biascorrected average\n",
      "ridge estimator given here appears to be novel as does the associated inference\n",
      "theory. Harding and Lovenheim (2017) analyze the role of prices in determining\n",
      "food purchases and nutrition and estimate the impact of taxes on nutrition and\n",
      "individual welfare. Allcott, H., B. B. Lockwood, and D. Taubinsky (2019) and\n",
      "Dubois, P., R. Gri ﬃth, and M. O’Connell (2019) 5 have also considered the\n",
      "welfare e ﬀects of taxing soda. Our results are complementary to theirs in the\n",
      "use of grocery store scanner data, allowance for nonparametric, general\n",
      "heterogeneity in the cross-section, including zeros in regressions, and in the\n",
      "comparison of cross-section and panelresults. 2 Demand and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example batch search\n",
    "queries = [\"query 1\", \"query 2\", \"query 3\"]\n",
    "batch_results = db.batch_search(queries)\n",
    "\n",
    "for df in batch_results:\n",
    "    print(f\"\\nResults for query: {df['query'].iloc[0]}\")\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"Score: {row['similarity']:.4f}\")\n",
    "        print(f\"Text: {textwrap.fill(row['text'], width=80)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
